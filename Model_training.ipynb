{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e4718d",
   "metadata": {},
   "source": [
    "# Introduction to JumpStart - Object Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f6a2e1c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb7649",
   "metadata": {},
   "source": [
    "---\n",
    "Welcome to Amazon [SageMaker JumpStart](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html)! You can use JumpStart to solve many Machine Learning tasks through one-click in SageMaker Studio, or through [SageMaker JumpStart API](https://sagemaker.readthedocs.io/en/stable/doc_utils/jumpstart.html). \n",
    "\n",
    "In this demo notebook, we demonstrate how to use the JumpStart API for Object Detection.  Object Detection refers to localizing objects in an image with a bounding box and predicting the classes of the objects. It can be used for counting objects, determining their exact locations and many more. It is applied to areas including security, surveillance, automated vehicle systems and machine inspection.\n",
    "\n",
    "In this notebook, we demonstrate two use cases of object detection models:\n",
    "\n",
    "* How to use pre-trained models trained on COCO dataset to do object detection.\n",
    "* How to use JumpStart transfer learning algorithm to train an Object Detection model on a custom dataset. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cdaa81",
   "metadata": {},
   "source": [
    "1. [Set Up](#1.-Set-Up)\n",
    "2. [Run inference on the pre-trained model](#2.-Run-inference-on-the-pre-trained-model)\n",
    "    * [Select a pre-trained model for inference](#2.1.-Select-a-pre-trained-model-for-inference)\n",
    "    * [Retrieve JumpStart Artifacts & Deploy an Endpoint](#2.2.-Retrieve-JumpStart-Artifacts-&-Deploy-an-Endpoint)\n",
    "    * [Download an example image for inference](#2.3.-Download-an-example-image-for-inference)\n",
    "    * [Query endpoint and parse response](#2.4.-Query-endpoint-and-parse-response)\n",
    "    * [Display model predictions](#2.5.-Display-model-predictions)\n",
    "    * [Clean up the endpoint](#2.6.-Clean-up-the-endpoint)\n",
    "\n",
    "\n",
    "3. [Fine-tune the pre-trained model on a custom dataset](#3.-Fine-tune-the-pre-trained-model-on-a-custom-dataset)\n",
    "    * [Retrieve Training Artifacts](#3.1.-Retrieve-Training-Artifacts)\n",
    "    * [Set Training parameters](#3.2.-Set-Training-parameters)\n",
    "    * [Train with Automatic Model Tuning (HPO)](#AMT)\n",
    "    * [Start Training](#3.4.-Start-Training)\n",
    "    * [Deploy and run inference on the fine-tuned model](#3.5.-Deploy-and-run-inference-on-the-fine-tuned-model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4aacaf",
   "metadata": {},
   "source": [
    "Note: This notebook was tested on ml.t3.medium instance in Amazon SageMaker Studio with Python 3 (Data Science) kernel and in Amazon SageMaker Notebook instance with conda_python3 kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1c8549",
   "metadata": {},
   "source": [
    "## 1. Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6135cae7",
   "metadata": {},
   "source": [
    "---\n",
    "Before executing the notebook, there are some initial steps required for set up. This notebook requires latest version of sagemaker and ipywidgets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbf1d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install sagemaker ipywidgets --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29d2512",
   "metadata": {},
   "source": [
    "### Permissions and environment variables\n",
    "\n",
    "---\n",
    "To train and host on Amazon SageMaker, we need to set up and authenticate the use of AWS services. Here, we use the execution role associated with the current notebook instance as the AWS account role with SageMaker access. It has necessary permissions, including access to your data in S3. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ce361cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "aws_role = get_execution_role()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e724c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Run inference on the pre-trained model\n",
    "\n",
    "***\n",
    "\n",
    "Using JumpStart, we can perform inference on the pre-trained model, even without fine-tuning it first on a new dataset. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a82e63",
   "metadata": {},
   "source": [
    "### 2.1. Select a pre-trained model for inference\n",
    "\n",
    "***\n",
    "Here, we download jumpstart model_manifest file from the jumpstart s3 bucket, filter-out all the Object Detection models and select a model for inference.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a36b7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models available for inference: 70\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import Dropdown\n",
    "\n",
    "# download JumpStart model_manifest file.\n",
    "boto3.client(\"s3\").download_file(\n",
    "    f\"jumpstart-cache-prod-{aws_region}\", \"models_manifest.json\", \"models_manifest.json\"\n",
    ")\n",
    "with open(\"models_manifest.json\", \"rb\") as json_file:\n",
    "    model_list = json.load(json_file)\n",
    "\n",
    "# filter-out all the Object Detection models from the manifest list.\n",
    "od_models = []\n",
    "for model in model_list:\n",
    "    model_id = model[\"model_id\"]\n",
    "    if (\"-od-\" in model_id or \"-od1-\" in model_id) and model_id not in od_models:\n",
    "        od_models.append(model_id)\n",
    "\n",
    "print(f\"Number of models available for inference: {len(od_models)}\")\n",
    "\n",
    "# display the model-ids in a dropdown to select a model for inference.\n",
    "infer_model_dropdown = Dropdown(\n",
    "    options=od_models,\n",
    "    value=\"pytorch-od-nvidia-ssd\",\n",
    "    description=\"Select a model:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"max-content\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaf71c1",
   "metadata": {},
   "source": [
    "#### Chose a model for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05fb5605",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07c838367134bfb8a3cb608d1822046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select a model:', index=17, layout=Layout(width='max-content'), options=('mxnet-od-fasteâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(infer_model_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d4b786",
   "metadata": {},
   "source": [
    "### 2.2. Retrieve JumpStart Artifacts & Deploy an Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39f542a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'xgboost-regression-snowflake' with wildcard version identifier '*'. You can pin to version '1.1.7' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/02/25 04:35:21] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Using model <span style=\"color: #008700; text-decoration-color: #008700\">'xgboost-regression-snowflake'</span> with wildcard version          <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/jumpstart/cache.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cache.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/jumpstart/cache.py#624\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">624</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         identifier <span style=\"color: #008700; text-decoration-color: #008700\">'*'</span>. You can pin to version <span style=\"color: #008700; text-decoration-color: #008700\">'1.1.7'</span> for more stable results.   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Note that models may have different input/output signatures after a major <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         version upgrade.                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/02/25 04:35:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Using model \u001b[38;2;0;135;0m'xgboost-regression-snowflake'\u001b[0m with wildcard version          \u001b]8;id=257303;file:///opt/conda/lib/python3.11/site-packages/sagemaker/jumpstart/cache.py\u001b\\\u001b[2mcache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=153697;file:///opt/conda/lib/python3.11/site-packages/sagemaker/jumpstart/cache.py#624\u001b\\\u001b[2m624\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         identifier \u001b[38;2;0;135;0m'*'\u001b[0m. You can pin to version \u001b[38;2;0;135;0m'1.1.7'\u001b[0m for more stable results.   \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Note that models may have different input/output signatures after a major \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         version upgrade.                                                          \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No instance type selected for inference hosting endpoint. Defaulting to ml.m5.xlarge.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> No instance type selected for inference hosting endpoint. Defaulting to   <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/jumpstart/factory/model.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/jumpstart/factory/model.py#238\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         ml.m5.xlarge.                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m No instance type selected for inference hosting endpoint. Defaulting to   \u001b]8;id=515810;file:///opt/conda/lib/python3.11/site-packages/sagemaker/jumpstart/factory/model.py\u001b\\\u001b[2mmodel.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=702026;file:///opt/conda/lib/python3.11/site-packages/sagemaker/jumpstart/factory/model.py#238\u001b\\\u001b[2m238\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         ml.m5.xlarge.                                                             \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Repacking model artifact                                                  <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/model.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/model.py#819\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">819</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">(</span>s3:<span style=\"color: #e100e1; text-decoration-color: #e100e1\">//jumpstart-cache-prod-us-east-1/xgboost-infer/infer-xgboost-regressi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #e100e1; text-decoration-color: #e100e1\">on-snowflake.tar.gz</span><span style=\"font-weight: bold\">)</span>, script artifact                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">(</span>s3:<span style=\"color: #e100e1; text-decoration-color: #e100e1\">//jumpstart-cache-prod-us-east-1/source-directory-tarballs/xgboost/in</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #e100e1; text-decoration-color: #e100e1\">ference/regression/v1.1.0/sourcedir.tar.gz</span><span style=\"font-weight: bold\">)</span>, and dependencies <span style=\"font-weight: bold\">([])</span> into   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         single tar.gz file located at                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         s3:<span style=\"color: #e100e1; text-decoration-color: #e100e1\">//sagemaker-us-east-1-462820966948/xgb-regression-snowflake-2025-04-02</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #e100e1; text-decoration-color: #e100e1\">-04-35-21-168/model.tar.gz.</span> This may take some time depending on model    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         size<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Repacking model artifact                                                  \u001b]8;id=714765;file:///opt/conda/lib/python3.11/site-packages/sagemaker/model.py\u001b\\\u001b[2mmodel.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=389453;file:///opt/conda/lib/python3.11/site-packages/sagemaker/model.py#819\u001b\\\u001b[2m819\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m(\u001b[0ms3:\u001b[38;2;225;0;225m/\u001b[0m\u001b[38;2;225;0;225m/jumpstart-cache-prod-us-east-1/xgboost-infer/\u001b[0m\u001b[38;2;225;0;225minfer-xgboost-regressi\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[38;2;225;0;225mon-snowflake.tar.gz\u001b[0m\u001b[1m)\u001b[0m, script artifact                                     \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m(\u001b[0ms3:\u001b[38;2;225;0;225m/\u001b[0m\u001b[38;2;225;0;225m/jumpstart-cache-prod-us-east-1/source-directory-tarballs/xgboost/in\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[38;2;225;0;225mference/regression/v1.1.0/\u001b[0m\u001b[38;2;225;0;225msourcedir.tar.gz\u001b[0m\u001b[1m)\u001b[0m, and dependencies \u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m into   \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         single tar.gz file located at                                             \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         s3:\u001b[38;2;225;0;225m/\u001b[0m\u001b[38;2;225;0;225m/sagemaker-us-east-1-462820966948/xgb-regression-snowflake-2025-04-02\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[38;2;225;0;225m-04-35-21-168/\u001b[0m\u001b[38;2;225;0;225mmodel.tar.gz.\u001b[0m This may take some time depending on model    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         size\u001b[33m...\u001b[0m                                                                   \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/02/25 04:35:24] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name:                                              <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         xgb-regression-snowflake-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-02-04-35-21-168                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/02/25 04:35:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name:                                              \u001b]8;id=7829;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=516997;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         xgb-regression-snowflake-\u001b[1;36m2025\u001b[0m-04-02-04-35-21-168                       \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/02/25 04:35:25] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#5889\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5889</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         xgb-regression-snowflake-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-02-04-35-21-174                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/02/25 04:35:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=41081;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=595271;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#5889\u001b\\\u001b[2m5889\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         xgb-regression-snowflake-\u001b[1;36m2025\u001b[0m-04-02-04-35-21-174                       \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4711\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4711</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         xgb-regression-snowflake-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-02-04-35-21-174                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=998114;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=588140;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4711\u001b\\\u001b[2m4711\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         xgb-regression-snowflake-\u001b[1;36m2025\u001b[0m-04-02-04-35-21-174                       \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "model = JumpStartModel(model_id=model_id)\n",
    "model_predictor = model.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0793fbab",
   "metadata": {},
   "source": [
    "### 2.3. Download an example image for inference\n",
    "---\n",
    "We download an example image from the JumpStart assets S3 bucket.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca582f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jumpstart_assets_s3_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
    "Naxos_Taverna_key_prefix = \"pytorch-metadata/assets\"\n",
    "Naxos_Taverna = \"Naxos_Taverna.jpg\"\n",
    "\n",
    "boto3.client(\"s3\").download_file(\n",
    "    jumpstart_assets_s3_bucket, f\"{Naxos_Taverna_key_prefix}/{Naxos_Taverna}\", Naxos_Taverna\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72450e0",
   "metadata": {},
   "source": [
    "### 2.4. Query endpoint and parse response\n",
    "\n",
    "---\n",
    "Input to the endpoint is a single image in binary format. Response of the endpoint is a set of bounding boxes as well as class names and scores for the bounding boxes. JumpStart allows the flexibility in the number of bounding boxes returned. Below, we show to predict two bounding boxes per image by appending `;n_predictions=2` to `Accept`. To predict xx boxes, one can change it to `;n_predictions=xx` or to get all the predicted boxes, one can remove `;n_predictions=2`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def query(model_predictor, image_file_name):\n",
    "    with open(image_file_name, \"rb\") as file:\n",
    "        input_img_rb = file.read()\n",
    "\n",
    "    query_response = model_predictor.predict(\n",
    "        input_img_rb,\n",
    "        {\n",
    "            \"ContentType\": \"application/x-image\",\n",
    "            \"Accept\": \"application/json;verbose;n_predictions=2\",\n",
    "        },\n",
    "    )\n",
    "    return query_response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = query_response\n",
    "    normalized_boxes, classes, scores, labels = (\n",
    "        model_predictions[\"normalized_boxes\"],\n",
    "        model_predictions[\"classes\"],\n",
    "        model_predictions[\"scores\"],\n",
    "        model_predictions[\"labels\"],\n",
    "    )\n",
    "    # Substitute the classes index with the classes name\n",
    "    class_names = [labels[int(idx)] for idx in classes]\n",
    "    return normalized_boxes, class_names, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f66921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_response = query(model_predictor, Naxos_Taverna)\n",
    "\n",
    "normalized_boxes, classes_names, confidences = parse_response(query_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceab8ce",
   "metadata": {},
   "source": [
    "### 2.5. Display model predictions\n",
    "---\n",
    "Next, we display the bounding boxes overlaid on the original image.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec666bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def display_predictions(img_jpg, normalized_boxes, classes_names, confidences):\n",
    "    colors = list(ImageColor.colormap.values())\n",
    "    image_np = np.array(Image.open(img_jpg))\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    ax = plt.axes()\n",
    "    ax.imshow(image_np)\n",
    "\n",
    "    for idx in range(len(normalized_boxes)):\n",
    "        left, bot, right, top = normalized_boxes[idx]\n",
    "        x, w = [val * image_np.shape[1] for val in [left, right - left]]\n",
    "        y, h = [val * image_np.shape[0] for val in [bot, top - bot]]\n",
    "        color = colors[hash(classes_names[idx]) % len(colors)]\n",
    "        rect = patches.Rectangle((x, y), w, h, linewidth=3, edgecolor=color, facecolor=\"none\")\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(\n",
    "            x,\n",
    "            y,\n",
    "            \"{} {:.0f}%\".format(classes_names[idx], confidences[idx] * 100),\n",
    "            bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb05d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_predictions(Naxos_Taverna, normalized_boxes, classes_names, confidences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6365132c",
   "metadata": {},
   "source": [
    "### 2.6. Clean up the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint\n",
    "model_predictor.delete_model()\n",
    "model_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc7587a",
   "metadata": {},
   "source": [
    "## 3. Fine-tune the pre-trained model on a custom dataset\n",
    "\n",
    "---\n",
    "Previously, we saw how to run inference on a pre-trained model. Next, we discuss how a model can be finetuned to a custom dataset with any number of classes. \n",
    "\n",
    "Transfer learning algorithm removes the object detection head of the pre-trained model and attaches a new randomly initialized head with number of classes same as the custom dataset. The fine-tuning step fine-tunes the last layer parameters while keeping the parameters of the rest of the model frozen, and returns the fine-tuned model. The objective during finetuning is to minimize box prediction error on the input data. \n",
    "\n",
    "Input to the algorithm must be a directory with sub-directoriey images and a file annotations.json. The input directory should look like below if the training data contains two images. The names of .png files\n",
    "can be anything. \n",
    "\n",
    "    input_directory\n",
    "        |--images\n",
    "            |--abc.png\n",
    "            |--def.png\n",
    "        |--annotations.json\n",
    "            \n",
    " \n",
    "The annotations.json file should have information for bounding_boxes and their class labels. It should have a \n",
    "dictionary with keys \"images\" and \"annotations\". Value for the \"images\" key should be a list of entries, \n",
    "one for each image of the form {\"file_name\": image_name, \"height\": height, \"width\": width, \"id\": image_id}. Value of the 'annotations' key should be a list of entries, one for each bounding box of the form {\"image_id\": image_id, \"bbox\": \\[xmin, ymin, xmax, ymax\\], \"category_id\": bbox_label}.\n",
    "\n",
    "We provide pennfudanped dataset as a default dataset for fine-tuning the model.\n",
    "PennFudanPed comprises images of pedestrians. The dataset has been downloaded from [here](https://www.cis.upenn.edu/~jshi/ped_html/#pub1). \n",
    "\n",
    "Citation:\n",
    "<sub><sup>\n",
    "@ONLINE {pennfudanped,\n",
    "author = \"Liming Wang1, Jianbo Shi2, Gang Song2, and I-fan Shen1\",\n",
    "title = \"Penn-Fudan Database for Pedestrian Detection and Segmentation\",\n",
    "year = \"2007\",\n",
    "url = \"https://www.cis.upenn.edu/~jshi/ped_html/\" }\n",
    "</sup></sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53c623",
   "metadata": {},
   "source": [
    "### 3.1. Retrieve Training Artifacts\n",
    "\n",
    "Here, we retrieve the training docker container, the training algorithm source, and the pre-trained base model. Note that model_version=\"*\" fetches the latest model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72eef73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris\n",
    "\n",
    "# Currently, not all the object detection models in jumpstart support finetuning. Thus, we manually select a model\n",
    "# which supports finetuning.\n",
    "train_model_id, train_model_version, train_scope = (\n",
    "    \"mxnet-od-ssd-512-vgg16-atrous-coco\",  # \"pytorch-od1-fasterrcnn-resnet50-fpn\"\n",
    "    \"*\",\n",
    "    \"training\",\n",
    ")\n",
    "training_instance_type = \"ml.m5.large\"\n",
    "\n",
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,  # automatically inferred from model_id\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    image_scope=train_scope,\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "# Retrieve the training script. This contains all the necessary files including data processing, model training etc.\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=train_scope\n",
    ")\n",
    "# Retrieve the pre-trained model tarball to further fine-tune\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, model_scope=train_scope\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf8779",
   "metadata": {},
   "source": [
    "### 3.2. Set Training parameters\n",
    "\n",
    "---\n",
    "Now that we are done with all the set up that is needed, we are ready to train our Object Detection model. To begin, let us create a [``sageMaker.estimator.Estimator``](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) object. This estimator will launch the training job. \n",
    "\n",
    "There are two kinds of parameters that need to be set for training. The first one are the parameters for the training job. These include: (i) Training data path. This is S3 folder in which the input data is stored, (ii) Output path: This the s3 folder in which the training output is stored. (iii) Training instance type: This indicates the type of machine on which to run the training. Typically, we use GPU instances for these training. We defined the training instance type above to fetch the correct train_image_uri. \n",
    "\n",
    "The second set of parameters are algorithm specific training hyper-parameters. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "990e1aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data is available in this bucket\n",
    "\n",
    "# Your S3 path\n",
    "training_data_bucket = \"lemondataset\"\n",
    "training_data_prefix = \"lemon-dataset/lemon-dataset/train/\"\n",
    "\n",
    "# Correct S3 training dataset path\n",
    "training_dataset_s3_path = f\"s3://{training_data_bucket}/{training_data_prefix}\"\n",
    "\n",
    "# Leave the rest as is\n",
    "output_bucket = sess.default_bucket()\n",
    "s3_bucket_prefix = \"jumpstart-example-od-training\"\n",
    "default_bucket_prefix = sess.default_bucket_prefix\n",
    "\n",
    "# If a default bucket prefix is specified, append it to the s3 path\n",
    "if default_bucket_prefix:\n",
    "    output_prefix = f\"{default_bucket_prefix}/{s3_bucket_prefix}\"\n",
    "else:\n",
    "    output_prefix = s3_bucket_prefix\n",
    "\n",
    "s3_output_location = f\"s3://{output_bucket}/{output_prefix}/output\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba9e6c8",
   "metadata": {},
   "source": [
    "---\n",
    "For algorithm specific hyper-parameters, we start by fetching python dictionary of the training hyper-parameters that the algorithm accepts with their default values. This can then be overridden to custom values.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "740a29e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': '10', 'adam-learning-rate': '0.01', 'batch-size': '4', 'reinitialize-top-layer': 'Auto', 'train-only-top-layer': 'True'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparameters = hyperparameters.retrieve_default(\n",
    "    model_id=train_model_id, model_version=train_model_version\n",
    ")\n",
    "\n",
    "# [Optional] Override default hyperparameters with custom values\n",
    "hyperparameters[\"epochs\"] = \"10\"\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108dfae",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.3. Train with Automatic Model Tuning ([HPO](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html)) <a id='AMT'></a>\n",
    "***\n",
    "Amazon SageMaker automatic model tuning, also known as hyperparameter tuning, finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose. We will use a [HyperparameterTuner](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html) object to interact with Amazon SageMaker hyperparameter tuning APIs.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be0a1097",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter\n",
    "\n",
    "# Use AMT for tuning and selecting the best model\n",
    "use_amt = True\n",
    "\n",
    "# Define objective metric per framework, based on which the best model will be selected.\n",
    "metric_definitions_per_model = {\n",
    "    \"mxnet\": {\n",
    "        \"metrics\": [{\"Name\": \"val_cross_entropy\", \"Regex\": \"Val_CrossEntropy=([0-9\\\\.]+)\"}],\n",
    "        \"type\": \"Minimize\",\n",
    "    },\n",
    "    \"pytorch\": {\n",
    "        \"metrics\": [{\"Name\": \"val_loss\", \"Regex\": \"val_loss: ([0-9\\\\.]+)\"}],\n",
    "        \"type\": \"Minimize\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# You can select from the hyperparameters supported by the model, and configure ranges of values to be searched for training the optimal model.(https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html)\n",
    "hyperparameter_ranges = {\n",
    "    \"adam-learning-rate\": ContinuousParameter(0.0001, 0.1, scaling_type=\"Logarithmic\")\n",
    "}\n",
    "\n",
    "# Increase the total number of training jobs run by AMT, for increased accuracy (and training time).\n",
    "max_jobs = 6\n",
    "# Change parallel training jobs run by AMT to reduce total training time, constrained by your account limits.\n",
    "# if max_jobs=max_parallel_jobs then Bayesian search turns to Random.\n",
    "max_parallel_jobs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a010d7",
   "metadata": {},
   "source": [
    "### 3.4. Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d47d7988-32e9-4d5a-b2c6-7877c11e4dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://lemondataset/lemon-dataset/lemon-dataset/train/'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset_s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc04ea5",
   "metadata": {},
   "source": [
    "---\n",
    "We start by creating the estimator object with all the required assets and then launch the training job.  It takes less than 10 mins on the default dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e0ae504-810f-4e15-a58d-19ef24100e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.tuner import HyperparameterTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c57a76-381e-4829-8639-82ab96baaa3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/03/25 05:07:00] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/03/25 05:07:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=512599;file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=43480;file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         jumpstart-example-mxnet-od-ssd-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>-vgg1-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-03-05-07-00-547        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=785149;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=523008;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         jumpstart-example-mxnet-od-ssd-\u001b[1;36m512\u001b[0m-vgg1-\u001b[1;36m2025\u001b[0m-04-03-05-07-00-547        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-03 05:07:02 Starting - Starting the training job...\n",
      "..25-04-03 05:07:17 Starting - Preparing the instances for training.\n",
      "..25-04-03 05:07:40 Downloading - Downloading input data.\n",
      "..25-04-03 05:08:16 Downloading - Downloading the training image.\n",
      "\u001b[34m2025-04-03 05:08:59,118 sagemaker-training-toolkit INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2025-04-03 05:08:59,120 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-04-03 05:08:59,123 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-04-03 05:08:59,137 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"adam-learning-rate\":\"0.01\",\"batch-size\":\"4\",\"epochs\":\"10\",\"reinitialize-top-layer\":\"Auto\",\"train-only-top-layer\":\"True\"}', 'SM_USER_ENTRY_POINT': 'transfer_learning.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"model\",\"training\"]', 'SM_CURRENT_HOST': 'algo-1', 'SM_CURRENT_INSTANCE_TYPE': 'ml.m5.large', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\"]', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}}', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[]', 'SM_IS_HETERO': 'false', 'SM_MODULE_NAME': 'transfer_learning', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '2', 'SM_NUM_GPUS': '0', 'SM_NUM_NEURONS': '0', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/mxnet/transfer_learning/od/prepack/v1.1.0/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.large\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"adam-learning-rate\":\"0.01\",\"batch-size\":\"4\",\"epochs\":\"10\",\"reinitialize-top-layer\":\"Auto\",\"train-only-top-layer\":\"True\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"jumpstart-example-mxnet-od-ssd-512-vgg1-2025-04-03-05-07-00-547\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/mxnet/transfer_learning/od/prepack/v1.1.0/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning.py\"}', 'SM_USER_ARGS': '[\"--adam-learning-rate\",\"0.01\",\"--batch-size\",\"4\",\"--epochs\",\"10\",\"--reinitialize-top-layer\",\"Auto\",\"--train-only-top-layer\",\"True\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_MODEL': '/opt/ml/input/data/model', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'SM_HP_ADAM-LEARNING-RATE': '0.01', 'SM_HP_BATCH-SIZE': '4', 'SM_HP_EPOCHS': '10', 'SM_HP_REINITIALIZE-TOP-LAYER': 'Auto', 'SM_HP_TRAIN-ONLY-TOP-LAYER': 'True'}\u001b[0m\n",
      "\u001b[34m2025-04-03 05:09:00,503 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing ./lib/numpy/numpy-1.23.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/opencv_python/opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[34mProcessing ./lib/sagemaker_jumpstart_prepack_script_utilities/sagemaker_jumpstart_prepack_script_utilities-1.0.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sagemaker-jumpstart-prepack-script-utilities, numpy, opencv-python\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.6.0.66\n",
      "    Uninstalling opencv-python-4.6.0.66:\n",
      "      Successfully uninstalled opencv-python-4.6.0.66\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mscipy 1.7.0 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.23.1 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed numpy-1.23.1 opencv-python-4.7.0.68 sagemaker-jumpstart-prepack-script-utilities-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.3.1 -> 25.0.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: python3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2025-04-03 05:09:05,624 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-04-03 05:09:05,627 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-04-03 05:09:05,643 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-04-03 05:09:05,645 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-04-03 05:09:05,660 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-04-03 05:09:05,663 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-04-03 05:09:05,675 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.large\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"adam-learning-rate\": \"0.01\",\n",
      "        \"batch-size\": \"4\",\n",
      "        \"epochs\": \"10\",\n",
      "        \"reinitialize-top-layer\": \"Auto\",\n",
      "        \"train-only-top-layer\": \"True\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.large\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"jumpstart-example-mxnet-od-ssd-512-vgg1-2025-04-03-05-07-00-547\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/mxnet/transfer_learning/od/prepack/v1.1.0/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"adam-learning-rate\":\"0.01\",\"batch-size\":\"4\",\"epochs\":\"10\",\"reinitialize-top-layer\":\"Auto\",\"train-only-top-layer\":\"True\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=transfer_learning.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"model\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.large\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=transfer_learning\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/mxnet/transfer_learning/od/prepack/v1.1.0/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.large\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"adam-learning-rate\":\"0.01\",\"batch-size\":\"4\",\"epochs\":\"10\",\"reinitialize-top-layer\":\"Auto\",\"train-only-top-layer\":\"True\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"jumpstart-example-mxnet-od-ssd-512-vgg1-2025-04-03-05-07-00-547\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/mxnet/transfer_learning/od/prepack/v1.1.0/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--adam-learning-rate\",\"0.01\",\"--batch-size\",\"4\",\"--epochs\",\"10\",\"--reinitialize-top-layer\",\"Auto\",\"--train-only-top-layer\",\"True\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_ADAM-LEARNING-RATE=0.01\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=4\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mSM_HP_REINITIALIZE-TOP-LAYER=Auto\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN-ONLY-TOP-LAYER=True\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 transfer_learning.py --adam-learning-rate 0.01 --batch-size 4 --epochs 10 --reinitialize-top-layer Auto --train-only-top-layer True\u001b[0m\n",
      "\u001b[34mExtension horovod.torch has not been built: /usr/local/lib/python3.8/dist-packages/horovod/torch/mpi_lib_v2.cpython-38-x86_64-linux-gnu.so not found\u001b[0m\n",
      "\u001b[34mIf this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\u001b[0m\n",
      "\u001b[34mWarning! MPI libs are missing, but python applications are still available.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\u001b[0m\n",
      "\u001b[34mCreating .rec file from /opt/ml/input/data/training/data_lst.lst in /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mmultiprocessing not available, fall back to single threaded encoding\u001b[0m\n",
      "\u001b[34mtime: 0.000553131103515625  count: 0\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\u001b[0m\n",
      "\u001b[34mCreating .rec file from /opt/ml/input/data/training/val_data_lst.lst in /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mmultiprocessing not available, fall back to single threaded encoding\u001b[0m\n",
      "\u001b[34mtime: 0.0005521774291992188  count: 0\u001b[0m\n",
      "\u001b[34mExtension horovod.torch has not been built: /usr/local/lib/python3.8/dist-packages/horovod/torch/mpi_lib_v2.cpython-38-x86_64-linux-gnu.so not found\u001b[0m\n",
      "\u001b[34mIf this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\u001b[0m\n",
      "\u001b[34mWarning! MPI libs are missing, but python applications are still available.\u001b[0m\n",
      "\u001b[34m[2025-04-03 05:09:13.381 ip-10-0-150-229.ec2.internal:41 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2025-04-03 05:09:13.503 ip-10-0-150-229.ec2.internal:41 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2025-04-03 05:09:13.504 ip-10-0-150-229.ec2.internal:41 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2025-04-03 05:09:13.504 ip-10-0-150-229.ec2.internal:41 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2025-04-03 05:09:13.505 ip-10-0-150-229.ec2.internal:41 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2025-04-03 05:09:13.505 ip-10-0-150-229.ec2.internal:41 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2025-04-03 05:09:13.511 ip-10-0-150-229.ec2.internal:41 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2025-04-03 05:09:13.515 ip-10-0-150-229.ec2.internal:41 INFO hook.py:485] Hook is writing from the hook with pid: 41\u001b[0m\n",
      "\u001b[34m'finetuned' not in model info file. Assuming model was not fine-tuned.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/mxnet/gluon/block.py:1443: UserWarning: \"SSD(\n",
      "  (features): VGGAtrousExtractor(\n",
      "    (stages): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(3 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(64 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "        (4): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): Activation(relu)\n",
      "      )\n",
      "      (3): HybridSequential(\n",
      "        (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "        (4): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): Activation(relu)\n",
      "      )\n",
      "      (4): HybridSequential(\n",
      "        (0): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "        (4): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): Activation(relu)\n",
      "      )\n",
      "      (5): HybridSequential(\n",
      "        (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1024 -> 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (norm4): Normalize(\n",
      "    \n",
      "    )\n",
      "    (extras): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "      (3): HybridSequential(\n",
      "        (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "      (4): HybridSequential(\n",
      "        (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(128 -> 256, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (class_predictors): HybridSequential(\n",
      "    (0): ConvPredictor(\n",
      "      (predictor): Conv2D(512 -> 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ConvPredictor(\n",
      "      (predictor): Conv2D(1024 -> 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ConvPredictor(\n",
      "      (predictor): Conv2D(512 -> 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (6): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (box_predictors): HybridSequential(\n",
      "    (0): ConvPredictor(\n",
      "      (predictor): Conv2D(512 -> 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ConvPredictor(\n",
      "      (predictor): Conv2D(1024 -> 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ConvPredictor(\n",
      "      (predictor): Conv2D(512 -> 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (6): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (anchor_generators): HybridSequential(\n",
      "    (0): SSDAnchorGenerator(\n",
      "    \n",
      "    )\n",
      "    (1): SSDAnchorGenerator(\n",
      "    \n",
      "    )\n",
      "    (2): SSDAnchorGenerator(\n",
      "    \n",
      "    )\n",
      "    (3): SSDAnchorGenerator(\n",
      "    \n",
      "    )\n",
      "    (4): SSDAnchorGenerator(\n",
      "    \n",
      "    )\n",
      "    (5): SSDAnchorGenerator(\n",
      "    \n",
      "    )\n",
      "    (6): SSDAnchorGenerator(\n",
      "    \n",
      "    )\n",
      "  )\n",
      "  (bbox_decoder): NormalizedBoxCenterDecoder(\n",
      "  \n",
      "  )\n",
      "  (cls_decoder): MultiPerClassDecoder(\n",
      "  \n",
      "  )\u001b[0m\n",
      "\u001b[34m)\" is being hybridized while still having forward hook/pre-hook. If \"SSD(\n",
      "  (features): VGGAtrousExtractor(\n",
      "    (stages): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(3 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(64 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "        (4): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): Activation(relu)\n",
      "      )\n",
      "      (3): HybridSequential(\n",
      "        (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "        (4): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): Activation(relu)\n",
      "      )\n",
      "      (4): HybridSequential(\n",
      "        (0): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "        (4): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): Activation(relu)\n",
      "      )\n",
      "      (5): HybridSequential(\n",
      "        (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1024 -> 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (norm4): Normalize(\n",
      "    \n",
      "    )\n",
      "    (extras): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "      (3): HybridSequential(\n",
      "        (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "      (4): HybridSequential(\n",
      "        (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(128 -> 256, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "        (3): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (class_predictors): HybridSequential(\n",
      "    (0): ConvPredictor(\n",
      "      (predictor): Conv2D(512 -> 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ConvPredictor(\n",
      "      (predictor): Conv2D(1024 -> 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ConvPredictor(\n",
      "      (predictor): Conv2D(512 -> 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (6): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (box_predictors): HybridSequential(\n",
      "    (0): ConvPredictor(\n",
      "      (predictor): Conv2D(512 -> 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ConvPredictor(\n",
      "      (predictor): Conv2D(1024 -> 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ConvPredictor(\n",
      "      (predictor): Conv2D(512 -> 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (6): ConvPredictor(\n",
      "      (predictor): Conv2D(256 -> 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (anchor_generators): HybridSequential(\n",
      "    (0): SSDAnchorGenerator(\n",
      "    \n",
      "    )\n",
      "    (1): SSDAnchorGenerator(\n",
      "    \n",
      "    )\n",
      "    (2): SSDAnchorGenerator(\n",
      "    \n",
      "    )\n",
      "    (3): SSDAnchorGenerator(\n",
      "    \n",
      "    )\n",
      "    (4): SSDAnchorGenerator(\n",
      "    \n",
      "    )\n",
      "    (5): SSDAnchorGenerator(\n",
      "    \n",
      "    )\n",
      "    (6): SSDAnchorGenerator(\n",
      "    \n",
      "    )\n",
      "  )\n",
      "  (bbox_decoder): NormalizedBoxCenterDecoder(\n",
      "  \n",
      "  )\n",
      "  (cls_decoder): MultiPerClassDecoder(\n",
      "  \n",
      "  )\u001b[0m\n",
      "\u001b[34m)\" is a child of HybridBlock, the hooks will not take effect.\n",
      "  warnings.warn('\"{block}\" is being hybridized while still having forward hook/pre-hook. '\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "training_job_name = name_from_base(f\"jumpstart-example-{train_model_id}-transfer-learning\")\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "od_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",  # Entry-point file in source_dir and present in train_source_uri.\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    "    base_job_name=training_job_name,\n",
    ")\n",
    "od_estimator.fit({\"training\": training_dataset_s3_path}, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab188c-ce76-443c-934a-2a25bf3a89fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99a147f2",
   "metadata": {},
   "source": [
    "### 3.5. Deploy and run inference on the fine-tuned model\n",
    "\n",
    "---\n",
    "\n",
    "A trained model does nothing on its own. We now want to use the model to perform inference. For this example, that means predicting the bounding boxes of an image. We follow the same steps as in [2. Run inference on the pre-trained model](#2.-Run-inference-on-the-pre-trained-model). We start by retrieving the jumpstart artifacts for deploying an endpoint. However, instead of base_predictor, we  deploy the `od_estimator` that we fine-tuned.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa8183",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_instance_type = \"ml.p2.xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,  # automatically inferred from model_id\n",
    "    image_scope=\"inference\",\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "# Retrieve the inference script uri. This includes scripts for model loading, inference handling etc.\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-example-FT-{train_model_id}-\")\n",
    "\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "finetuned_predictor = (hp_tuner if use_amt else od_estimator).deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    entry_point=\"inference.py\",  # entry point file in source_dir and present in deploy_source_uri\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcbd4de",
   "metadata": {},
   "source": [
    "---\n",
    "Next, we download an example pedestrian image from the S3 bucket for inference.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "jumpstart_assets_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
    "pedestrian_image_key = \"training-datasets/PennFudanPed_COCO_format/images\"\n",
    "pedestrian_image_file_name = \"FudanPed00001.png\"\n",
    "\n",
    "boto3.client(\"s3\").download_file(\n",
    "    jumpstart_assets_bucket,\n",
    "    f\"{pedestrian_image_key}/{pedestrian_image_file_name}\",\n",
    "    pedestrian_image_file_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66970f6d",
   "metadata": {},
   "source": [
    "---\n",
    "Next, we query the finetuned model, parse the response and display the predictions. Functions for these are implemented in sections [2.4. Query endpoint and parse response](#2.4.-Query-endpoint-and-parse-response) and [2.5. Display model predictions](#2.5.-Display-model-predictions)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daeddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_response = query(finetuned_predictor, pedestrian_image_file_name)\n",
    "\n",
    "normalized_boxes, classes_names, confidences = parse_response(query_response)\n",
    "display_predictions(pedestrian_image_file_name, normalized_boxes, classes_names, confidences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb35b8f",
   "metadata": {},
   "source": [
    "---\n",
    "Next, we delete the endpoint corresponding to the finetuned model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f870b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint\n",
    "finetuned_predictor.delete_model()\n",
    "finetuned_predictor.delete_endpoint()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "578a74e2",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/introduction_to_amazon_algorithms|jumpstart_object_detection|Amazon_JumpStart_Object_Detection.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
